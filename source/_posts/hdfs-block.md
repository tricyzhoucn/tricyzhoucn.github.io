---
title: hdfs-block
date: 2022-12-14 09:48:41
tags: HDFS
---

> HDFS block介绍

### 介绍

HDFS文件在物理上是分块存储(block)，块大小通过参数dfs.blocksize控制，hadoop2.x默认128M，老版本64M；

HDFS的设计特点：

1）可以进行超大文件存储

2）对商用硬件要求不高，可以在廉价机器上运行

3）流式数据访问：适合一次写入，多次读出的场景，适合用来做数据分析，并不适合做网盘应用等文件系统

4）HDFS只支持单个写入者，而且文件的写入只能以“添加”方式在文件末尾写数据

5）因为NameNode的原因，不适合大量小文件的存储

6）数据访问的延迟相对较高，不适合进行低延迟处理

默认128M因为**最佳传输损耗理论**：在一次传输中，寻址时间占总传输时间的1%时，本次传输损耗最小，为最佳性价比传输，目前硬件的发展条件，普通磁盘写速率大概为100M/s，寻址时间10ms，10ms/1%=1s，1s*100M/s=100M，块传输每64k校验一次，因此块大小必须为2的n方，最接近100M的就是128M；

实际开发中要把block设置远大于128MB，比如存储文件是1TB，一般把block大小设置为512MB，但是也不能设置特别大，因为mapreduce任务中map一次只处理一个块中的数据（默认切片大小等于block大小），如果设置太大，任务数就会少，任务运行速度慢；

如果文件小于块大小，不会占用整个块；

如果是固态硬盘，写速度300M/s，块调整到256M；如果是固态硬盘，写速度500M/s，块调整到512M；

不能太大：1）在一些分块读取的场景，不够灵活，会带来额外的网络消耗；2）在上传文件时，一旦发生故障，会造成资源的浪费；

不能太小：1）块太小，同样大小的文件会占用过多的NameNode的元数据空间；2）块太小，在进行读写操作时，会消耗额外的寻址时间；

块缓存：通常DataNode从磁盘读取块，但是对于频繁访问的数据块，DataNode会将其缓存到DataNode节点内存中，以堆外缓存形式存在。默认情况下，一个块只会缓存到一个DataNode内存中，这样计算框架就可以在缓存块上进行计算任务，大大提高读操作性能，进而提高任务效率；

### 参考

https://www.cnblogs.com/sunbr/p/13262242.html

https://blog.csdn.net/qq_26442553/article/details/79117897
